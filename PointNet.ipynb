{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "5tlGVKVeI42R",
        "outputId": "ab5159fa-68af-4232-c46e-9df301856107"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
            "[Open3D INFO] WebRTC GUI backend enabled.\n",
            "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "import open3d as o3d\n",
        "from pathlib import Path\n",
        "import zipfile\n",
        "import requests\n",
        "import os\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not Path(\"ModelNet10\").exists():\n",
        "    req = requests.get(r\"http://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip\")\n",
        "    \n",
        "    path = \"ModelNet10.zip\"\n",
        "\n",
        "    with open(path, \"wb\") as f:\n",
        "        f.write(req.content)\n",
        "\n",
        "    with zipfile.ZipFile(path, \"r\") as f:\n",
        "        f.extractall()\n",
        "\n",
        "    os.remove(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6oYSf76iA_d"
      },
      "source": [
        "## Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "aRHv0wjiiAbF"
      },
      "outputs": [],
      "source": [
        "class ModelNetDataSet(Dataset):\n",
        "  def __init__(self, path: Path, point_range=(1000, 25_000), test=False):\n",
        "    super(ModelNetDataSet, self).__init__()\n",
        "    if isinstance(path, str):\n",
        "      path = Path(path)\n",
        "\n",
        "    self.point_range = point_range\n",
        "    self.categories = [x.name for x in path.iterdir() if x.is_dir()]\n",
        "\n",
        "    self.items = []\n",
        "    for directory in path.iterdir():\n",
        "      if not directory.is_dir(): continue\n",
        "\n",
        "      item_dir = directory / \"test\" if test else directory / \"train\"\n",
        "\n",
        "      for item in item_dir.iterdir():\n",
        "        self.items.append(item)\n",
        "\n",
        "\n",
        "\n",
        "  def __get_item__(self, index):\n",
        "    model_path = self.items[index]\n",
        "    mesh = o3d.io.read_triangle_mesh(str(model_path))\n",
        "\n",
        "    return torch.tensor(np.asarray(mesh.sample_points_uniformly(number_of_points=torch.randint(*self.point_range, (1, ))[0]).points)), model_path.parent.parent.name\n",
        "\n",
        "  def __len__(self):\n",
        "    len(self.items)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "'NoneType' object cannot be interpreted as an integer",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\chris\\Documents\\Projects\\ML\\PointNet\\pointnet.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chris/Documents/Projects/ML/PointNet/pointnet.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data \u001b[39m=\u001b[39m ModelNetDataSet(\u001b[39m\"\u001b[39m\u001b[39mModelNet10\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/chris/Documents/Projects/ML/PointNet/pointnet.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mlen\u001b[39;49m(data)\n",
            "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object cannot be interpreted as an integer"
          ]
        }
      ],
      "source": [
        "data = ModelNetDataSet(\"ModelNet10\")\n",
        "len(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srR5PI2FiF6Z"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-BFZvTh6A9j"
      },
      "outputs": [],
      "source": [
        "class TNet(nn.Module):\n",
        "\n",
        "  def __init__(self, dim):\n",
        "    super(TNet, self).__init__()\n",
        "\n",
        "    self.dim = dim\n",
        "\n",
        "    self.conv_1 = nn.Conv1d(dim, 64, kernel_size=1)\n",
        "    self.conv_2 = nn.Conv1d(64, 128, kernel_size=1)\n",
        "    self.conv_3 = nn.Conv1d(128, 1024, kernel_size=1)\n",
        "\n",
        "    self.linear_1 = nn.Linear(1024, 512)\n",
        "    self.linear_2 = nn.Linear(512, 256)\n",
        "    self.linear_3 = nn.Linear(256, dim*dim)\n",
        "\n",
        "    self.bns = [nn.BatchNorm(x) for x in (64, 128, 1024, 512, 256)]\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x.shape = [batch, n, 3]\n",
        "\n",
        "    x = self.bns[0](F.relu(self.conv_1(x)))\n",
        "    x = self.bns[1](F.relu(self.conv_2(x)))\n",
        "    x = self.bns[2](F.relu(self.conv_3(x)))\n",
        "\n",
        "    # Check this dimension\n",
        "    x.max(dim=1)\n",
        "\n",
        "    x = self.bns[3](F.relu(self.linear_1(x)))\n",
        "    x = self.bns[4](F.relu(self.linear_2(x)))\n",
        "    x = self.linear_3(x)\n",
        "\n",
        "    # x.shape = [batch, self.dim**2]\n",
        "    # Not sure if the requires grad is needed here\n",
        "    identity = torch.eye(self.dim, requires_grad=True)\n",
        "\n",
        "    if x.is_cuda():\n",
        "      identity.cuda()\n",
        "\n",
        "    return x.view(-1, self.dim, self.dim) + identity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAG4JkLv-l3q"
      },
      "outputs": [],
      "source": [
        "class PointNetBackBone(nn.Module):\n",
        "  def __init__(self, dims=(3, 64, 128, 1024), local_features=True):\n",
        "    super(PointNetBackBone, self).__init__()\n",
        "\n",
        "    self.dims = dims\n",
        "    self.local_features = local_features\n",
        "\n",
        "    self.tnet_1 = TNet(dims[0])\n",
        "    self.tnet_2 = TNet(dims[1])\n",
        "\n",
        "    self.conv_1 = nn.Conv1d(dims[0], dims[1], kernel_size=1)\n",
        "    self.conv_2 = nn.Conv1d(dims[1], dims[1], kernel_size=1)\n",
        "\n",
        "    self.conv_3 = nn.Conv1d(dims[1], dims[1], kernel_size=1)\n",
        "    self.conv_4 = nn.Conv1d(dims[1], dims[2], kernel_size=1)\n",
        "    self.conv_5 = nn.Conv1d(dims[2], dims[3], kernel_size=1)\n",
        "\n",
        "    self.bns = [nn.BatchNorm(x) for x in (dims[1], dims[1], dims[1], dims[2], dims[3])]\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x.shape = [batch, n, dim_1]\n",
        "\n",
        "    # transform.shape = [batch, dim_1, dim_1]\n",
        "    transform = self.tnet_1(x)\n",
        "    # (transform[:, None]@x[...,None]).shape = [batch, n, dim_2, 1]\n",
        "    x = (transform[:, None]@x[...,None]).squeeze()\n",
        "\n",
        "    x = self.bns[0](F.relu(self.conv_1(x)))\n",
        "    x = self.bns[1](F.relu(self.conv_2(x)))\n",
        "\n",
        "    transform_2 = self.tnet_2(x)\n",
        "    # (transform_2[:, None]@x[..., None]).shape = [batch, n, dim_2, dim_2]\n",
        "    x = (transform_2[:, None]@x[..., None]).squeeze()\n",
        "\n",
        "    if self.local_features:\n",
        "      # local_features.shape = [batch, n, dim_2]\n",
        "      local_features = x.clone()\n",
        "\n",
        "    x = self.bns[2](F.relu(self.conv_3(x)))\n",
        "    x = self.bns[3](F.relu(self.conv_4(x)))\n",
        "    x = self.bns[4](F.relu(self.conv_5(x)))\n",
        "\n",
        "    # x.shape = [batch, n, 1024]\n",
        "    global_features = x.max(dim=1)\n",
        "\n",
        "    if self.local_features:\n",
        "      features = torch.cat((local_features, global_features), dim=2)\n",
        "      return features, transform, transform_2\n",
        "    else:\n",
        "      return global_features, transform, transform_2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rHtb9pcMQps"
      },
      "outputs": [],
      "source": [
        "class PointNetClassificationHead(nn.Module):\n",
        "\n",
        "  def __init__(self, outputs, layers, dims=None, keep=0.7):\n",
        "    super(PointNetClassificationHead, self).__init__()\n",
        "\n",
        "    if dims is None:\n",
        "      self.backbone = PointNetBackBone(local_features=False)\n",
        "      if layers[0] != 1024: raise ValueError(f\"Dimensions don't match. {layers[0]} != 1024\")\n",
        "    else:\n",
        "      self.backbone = PointNetBackBone(dims, False)\n",
        "      if layers[0] != dims[-1]: raise ValueError(f\"Dimensions don't match. {layers[0]} != {dims[-1]}\")\n",
        "\n",
        "    self.layers = [(nn.BatchNorm1d(y), nn.Linear(x, y)) for x, y in zip(layers[:-1], layers[1:])]\n",
        "    self.output = nn.Linear(layers[-2], layers[-1])\n",
        "    self.dropout = nn.Dropout(p=1 - keep)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x, t1, t2 = self.backbone(x)\n",
        "\n",
        "    for batch, linear in self.layers:\n",
        "      x = batch(F.relu(linear(x)))\n",
        "\n",
        "    x = self.dropout(x)\n",
        "    x = self.output(x)\n",
        "\n",
        "    return F.log_softmax(x, dim=1), t1, t2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0VrTjJgiI08"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6jStxnzt_fu"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def loss_function(x, y, t1: torch.Tensor, t2: torch.Tensor, alpha=1E-3): \n",
        "    nll_loss = F.nll_loss(x, y)\n",
        "    t1_loss = (np.eye(t1.shape[0]) - t1@t1.transpose(1,2)).norm(p=\"fro\")\n",
        "    t2_loss = (np.eye(t1.shape[0]) - t2@t2.transpose(1,2)).norm(p=\"fro\")\n",
        "\n",
        "    return nll_loss + t1_loss*alpha + t2_loss*alpha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Learner:\n",
        "\n",
        "    def __init__(self, model, optimiser, loss, dataset):\n",
        "        self.model = model\n",
        "        self.optimiser = optimiser\n",
        "        self.loss = loss\n",
        "        self.dataset = dataset\n",
        "\n",
        "    def one_epoch(self, batch_size):\n",
        "        for i, data in enumerate(self.dataset):\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_one_epoch(epoch_index, tb_writer):\n",
        "    running_loss = 0.\n",
        "    last_loss = 0.\n",
        "\n",
        "    # Here, we use enumerate(training_loader) instead of\n",
        "    # iter(training_loader) so that we can track the batch\n",
        "    # index and do some intra-epoch reporting\n",
        "    for i, data in enumerate(training_loader):\n",
        "        # Every data instance is an input + label pair\n",
        "        inputs, labels = data\n",
        "\n",
        "        # Zero your gradients for every batch!\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Make predictions for this batch\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Compute the loss and its gradients\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        # Adjust learning weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # Gather data and report\n",
        "        running_loss += loss.item()\n",
        "        if i % 1000 == 999:\n",
        "            last_loss = running_loss / 1000 # loss per batch\n",
        "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
        "            tb_x = epoch_index * len(training_loader) + i + 1\n",
        "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
        "            running_loss = 0.\n",
        "\n",
        "    return last_loss"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
