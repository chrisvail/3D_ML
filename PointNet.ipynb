{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "5tlGVKVeI42R",
        "outputId": "ab5159fa-68af-4232-c46e-9df301856107"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "import open3d as o3d\n",
        "from pathlib import Path\n",
        "import zipfile\n",
        "import requests\n",
        "import os\n",
        "import numpy as np\n",
        "from contextlib import contextmanager"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not Path(\"ModelNet10\").exists():\n",
        "    req = requests.get(r\"http://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip\")\n",
        "    \n",
        "    path = \"ModelNet10.zip\"\n",
        "\n",
        "    with open(path, \"wb\") as f:\n",
        "        f.write(req.content)\n",
        "\n",
        "    with zipfile.ZipFile(path, \"r\") as f:\n",
        "        f.extractall()\n",
        "\n",
        "    os.remove(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6oYSf76iA_d"
      },
      "source": [
        "## Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aRHv0wjiiAbF"
      },
      "outputs": [],
      "source": [
        "class ModelNetDataSet(Dataset):\n",
        "  def __init__(self, path: Path, point_range=(1000, 25_000), test=False):\n",
        "    super(ModelNetDataSet, self).__init__()\n",
        "    if isinstance(path, str):\n",
        "      path = Path(path)\n",
        "\n",
        "    self.point_range = point_range\n",
        "    self.categories = [x.name for x in path.iterdir() if x.is_dir()]\n",
        "\n",
        "    self.items = []\n",
        "    for directory in path.iterdir():\n",
        "      if not directory.is_dir(): continue\n",
        "\n",
        "      item_dir = directory / \"test\" if test else directory / \"train\"\n",
        "\n",
        "      for item in item_dir.iterdir():\n",
        "        self.items.append(item)\n",
        "\n",
        "\n",
        "\n",
        "  def __get_item__(self, index):\n",
        "    model_path = self.items[index]\n",
        "    mesh = o3d.io.read_triangle_mesh(str(model_path))\n",
        "\n",
        "    return torch.tensor(np.asarray(mesh.sample_points_uniformly(number_of_points=torch.randint(*self.point_range, (1, ))[0]).points)), model_path.parent.parent.name\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.items)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3994"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = ModelNetDataSet(\"ModelNet10\", test=False)\n",
        "len(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srR5PI2FiF6Z"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "q-BFZvTh6A9j"
      },
      "outputs": [],
      "source": [
        "class TNet(nn.Module):\n",
        "\n",
        "  def __init__(self, dim):\n",
        "    super(TNet, self).__init__()\n",
        "\n",
        "    self.dim = dim\n",
        "\n",
        "    self.conv_1 = nn.Conv1d(dim, 64, kernel_size=1)\n",
        "    self.conv_2 = nn.Conv1d(64, 128, kernel_size=1)\n",
        "    self.conv_3 = nn.Conv1d(128, 1024, kernel_size=1)\n",
        "\n",
        "    self.linear_1 = nn.Linear(1024, 512)\n",
        "    self.linear_2 = nn.Linear(512, 256)\n",
        "    self.linear_3 = nn.Linear(256, dim*dim)\n",
        "\n",
        "    self.bns = [nn.BatchNorm(x) for x in (64, 128, 1024, 512, 256)]\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x.shape = [batch, n, 3]\n",
        "\n",
        "    x = self.bns[0](F.relu(self.conv_1(x)))\n",
        "    x = self.bns[1](F.relu(self.conv_2(x)))\n",
        "    x = self.bns[2](F.relu(self.conv_3(x)))\n",
        "\n",
        "    # Check this dimension\n",
        "    x.max(dim=1)\n",
        "\n",
        "    x = self.bns[3](F.relu(self.linear_1(x)))\n",
        "    x = self.bns[4](F.relu(self.linear_2(x)))\n",
        "    x = self.linear_3(x)\n",
        "\n",
        "    # x.shape = [batch, self.dim**2]\n",
        "    # Not sure if the requires grad is needed here\n",
        "    identity = torch.eye(self.dim, requires_grad=True)\n",
        "\n",
        "    if x.is_cuda():\n",
        "      identity.cuda()\n",
        "\n",
        "    return x.view(-1, self.dim, self.dim) + identity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hAG4JkLv-l3q"
      },
      "outputs": [],
      "source": [
        "class PointNetBackBone(nn.Module):\n",
        "  def __init__(self, dims=(3, 64, 128, 1024), local_features=True):\n",
        "    super(PointNetBackBone, self).__init__()\n",
        "\n",
        "    self.dims = dims\n",
        "    self.local_features = local_features\n",
        "\n",
        "    self.tnet_1 = TNet(dims[0])\n",
        "    self.tnet_2 = TNet(dims[1])\n",
        "\n",
        "    self.conv_1 = nn.Conv1d(dims[0], dims[1], kernel_size=1)\n",
        "    self.conv_2 = nn.Conv1d(dims[1], dims[1], kernel_size=1)\n",
        "\n",
        "    self.conv_3 = nn.Conv1d(dims[1], dims[1], kernel_size=1)\n",
        "    self.conv_4 = nn.Conv1d(dims[1], dims[2], kernel_size=1)\n",
        "    self.conv_5 = nn.Conv1d(dims[2], dims[3], kernel_size=1)\n",
        "\n",
        "    self.bns = [nn.BatchNorm(x) for x in (dims[1], dims[1], dims[1], dims[2], dims[3])]\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x.shape = [batch, n, dim_1]\n",
        "\n",
        "    # transform.shape = [batch, dim_1, dim_1]\n",
        "    transform = self.tnet_1(x)\n",
        "    # (transform[:, None]@x[...,None]).shape = [batch, n, dim_2, 1]\n",
        "    x = (transform[:, None]@x[...,None]).squeeze()\n",
        "\n",
        "    x = self.bns[0](F.relu(self.conv_1(x)))\n",
        "    x = self.bns[1](F.relu(self.conv_2(x)))\n",
        "\n",
        "    transform_2 = self.tnet_2(x)\n",
        "    # (transform_2[:, None]@x[..., None]).shape = [batch, n, dim_2, dim_2]\n",
        "    x = (transform_2[:, None]@x[..., None]).squeeze()\n",
        "\n",
        "    if self.local_features:\n",
        "      # local_features.shape = [batch, n, dim_2]\n",
        "      local_features = x.clone()\n",
        "\n",
        "    x = self.bns[2](F.relu(self.conv_3(x)))\n",
        "    x = self.bns[3](F.relu(self.conv_4(x)))\n",
        "    x = self.bns[4](F.relu(self.conv_5(x)))\n",
        "\n",
        "    # x.shape = [batch, n, 1024]\n",
        "    global_features = x.max(dim=1)\n",
        "\n",
        "    if self.local_features:\n",
        "      features = torch.cat((local_features, global_features), dim=2)\n",
        "      return features, transform, transform_2\n",
        "    else:\n",
        "      return global_features, transform, transform_2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6rHtb9pcMQps"
      },
      "outputs": [],
      "source": [
        "class PointNetClassificationHead(nn.Module):\n",
        "\n",
        "  def __init__(self, outputs, layers, dims=None, keep=0.7):\n",
        "    super(PointNetClassificationHead, self).__init__()\n",
        "\n",
        "    if dims is None:\n",
        "      self.backbone = PointNetBackBone(local_features=False)\n",
        "      if layers[0] != 1024: raise ValueError(f\"Dimensions don't match. {layers[0]} != 1024\")\n",
        "    else:\n",
        "      self.backbone = PointNetBackBone(dims, False)\n",
        "      if layers[0] != dims[-1]: raise ValueError(f\"Dimensions don't match. {layers[0]} != {dims[-1]}\")\n",
        "\n",
        "    self.layers = [(nn.BatchNorm1d(y), nn.Linear(x, y)) for x, y in zip(layers[:-1], layers[1:])]\n",
        "    self.output = nn.Linear(layers[-2], layers[-1])\n",
        "    self.dropout = nn.Dropout(p=1 - keep)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x, t1, t2 = self.backbone(x)\n",
        "\n",
        "    for batch, linear in self.layers:\n",
        "      x = batch(F.relu(linear(x)))\n",
        "\n",
        "    x = self.dropout(x)\n",
        "    x = self.output(x)\n",
        "\n",
        "    return F.log_softmax(x, dim=1), t1, t2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0VrTjJgiI08"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "g6jStxnzt_fu"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mSGD(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m, momentum\u001b[39m=\u001b[39m\u001b[39m0.9\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "# optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def loss_function(x, y, t1: torch.Tensor, t2: torch.Tensor, alpha=1E-3): \n",
        "    nll_loss = F.nll_loss(x, y)\n",
        "    t1_loss = (np.eye(t1.shape[0]) - t1@t1.transpose(1,2)).norm(p=\"fro\")\n",
        "    t2_loss = (np.eye(t1.shape[0]) - t2@t2.transpose(1,2)).norm(p=\"fro\")\n",
        "\n",
        "    return nll_loss + t1_loss*alpha + t2_loss*alpha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_one_epoch(epoch_index, tb_writer):\n",
        "    running_loss = 0.\n",
        "    last_loss = 0.\n",
        "\n",
        "    # Here, we use enumerate(training_loader) instead of\n",
        "    # iter(training_loader) so that we can track the batch\n",
        "    # index and do some intra-epoch reporting\n",
        "    for i, data in enumerate(training_loader):\n",
        "        # Every data instance is an input + label pair\n",
        "        inputs, labels = data\n",
        "\n",
        "        # Zero your gradients for every batch!\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Make predictions for this batch\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Compute the loss and its gradients\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        # Adjust learning weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # Gather data and report\n",
        "        running_loss += loss.item()\n",
        "        if i % 1000 == 999:\n",
        "            last_loss = running_loss / 1000 # loss per batch\n",
        "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
        "            tb_x = epoch_index * len(training_loader) + i + 1\n",
        "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
        "            running_loss = 0.\n",
        "\n",
        "    return last_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'epochs' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m epochs:\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m     \u001b[39m# This needs some tqdm magic to give me stats\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[39m# Chunking happens with dataloader\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[39mfor\u001b[39;00m data, labels \u001b[39min\u001b[39;00m chunked_mini_batch:\n\u001b[1;32m      6\u001b[0m         \u001b[39m# Needs to be data augmentation here\u001b[39;00m\n\u001b[1;32m      7\u001b[0m         \u001b[39m#   1. Resampling of the input mesh \u001b[39;00m\n\u001b[1;32m      8\u001b[0m         \u001b[39m#   2. Jitter on the points\u001b[39;00m\n\u001b[1;32m      9\u001b[0m         \u001b[39m#   3. Random transform on the points\u001b[39;00m\n\u001b[1;32m     10\u001b[0m         optimizer\u001b[39m.\u001b[39mzero_grad()\n",
            "\u001b[0;31mNameError\u001b[0m: name 'epochs' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "for i in epochs:\n",
        "\n",
        "    # This needs some tqdm magic to give me stats\n",
        "    # Chunking happens with dataloader\n",
        "    for data, labels in chunked_mini_batch:\n",
        "        # Needs to be data augmentation here\n",
        "        #   1. Resampling of the input mesh \n",
        "        #   2. Jitter on the points\n",
        "        #   3. Random transform on the points\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        ys, t1s, t2s = model(data)\n",
        "\n",
        "        loss = loss_function(data, ys, t1s, t2s)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "3D_ML",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "027e515360b94f8508ce087551c413c792ad912dc979b64fe23c60a60c965b82"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
