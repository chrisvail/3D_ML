{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learner Framework\n",
    "\n",
    "This is the core framework I'm going to be using to run the training of all the ML models in this repository. It's based of the FastAI miniAI learner class from the Deep learning for coders part 2 course but with minor tweaks and refactoring. Partially so I can make sure I understand how it works and partly because I don't entirely agree with the coding style used in the course. \n",
    "\n",
    "I want to make this a very flexible framework for working on basically any model I could need. I'm going to do this using a callback heavy architecture - kind of like the strategy pattern except with a lot of interior mutablity. The callbacks will have access to the learner itself and be able to change basically anything about it. What this will mean is that theres a lot of instance variables for things that would normally just exist in the class like the current epoch number. \n",
    "\n",
    "Callbacks themselves need to inherit from the Callbacks class which quite frankly is barely an implementation. All it does is default an priority value which dictates the order in which callbacks. In the documentation I will endeavour to keep a list of all the methods that can be called in the Learners train method. The way it's done means there isnt an explicit set of methods that could be called (How very unrust of me. Luckily this isn't Rust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Callback:\n",
    "    \"\"\" Base class for callbacks for the Learner class. This should never be instantiated on it's own. \n",
    "    It wouldn't do anything if you did but it would be a waste of time. \n",
    "\n",
    "    Below is a list of all the methods that could be run by the Learner Class. Do note that each one has 2 variants \"before_\" and \"after_\" prepended to the name.\n",
    "        - \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    priority=0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CancelTrainException(Exception): pass\n",
    "class CancelEpochException(Exception): pass\n",
    "class CancelBatchException(Exception): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner:\n",
    "\n",
    "    def __init__(self, model, optimiser, loss_func, dataloaders, callbacks=None):\n",
    "        self.model = model\n",
    "        self.optimiser = optimiser\n",
    "        self.loss_func = loss_func\n",
    "        self.dataloaders = dataloaders\n",
    "        self.callbacks = [] if callbacks is None else list(callbacks)\n",
    "\n",
    "    def one_epoch(self):\n",
    "        for j, (data, labels) in enumerate(self.train_dataset):\n",
    "            self.batch_num = j\n",
    "            self.data = data\n",
    "            self.labels = labels\n",
    "            try:\n",
    "                with self._callback_manager(\"batch\"):\n",
    "                    self.optimiser.zero_grad()\n",
    "\n",
    "                    self.predictions = self.model(self.data)\n",
    "\n",
    "                    self.loss = self.loss_func(self.predictions, self.labels)\n",
    "\n",
    "                    self.loss.backward()\n",
    "\n",
    "                    self.optimiser.step()\n",
    "            except CancelBatchException:\n",
    "                pass\n",
    "\n",
    "\n",
    "    def train(self, epochs=1, learning_rate=1E-3, validation_epochs=1):\n",
    "        self.num_epochs = epochs\n",
    "        try: \n",
    "            with self._callback_manager(\"train\"):\n",
    "                for i in range(epochs):\n",
    "                    self.epoch = i\n",
    "                    if \"train\" in self.dataloaders:\n",
    "                        try: \n",
    "                            with self._callback_manager(\"epoch\"):\n",
    "                                self.one_epoch()\n",
    "                        except CancelEpochException:\n",
    "                            pass\n",
    "                        finally: \n",
    "                            if \"validation\" in self.dataloaders and self.epoch % validation_epochs == 0: \n",
    "                                self._validate()\n",
    "        except CancelTrainException:\n",
    "            pass\n",
    "\n",
    "        if \"test\" in self.dataloaders:\n",
    "            self._test()\n",
    "\n",
    "    \n",
    "    def _validate(self):\n",
    "        with torch.no_grad():\n",
    "            for i, (data, labels) in enumerate(self.dataloaders[\"validation\"]):\n",
    "                self.data, self.labels = data, labels\n",
    "                with self._callback_manager(\"validation_batch\"):\n",
    "                    self.validation_predictions = self.model(self.data, self.labels)\n",
    "                    self.validation_loss_batch = self.loss_func(self.predictions, self.labels)\n",
    "\n",
    "                    if i:\n",
    "                        self.validation_loss = self.accumulate_loss(self.validation_loss, self.validation_loss_batch)\n",
    "                    else:\n",
    "                        self.validation_loss = self.validation_loss_batch\n",
    "\n",
    "    def _test(self):\n",
    "        with torch.no_grad():\n",
    "            for i, (data, labels) in enumerate(self.dataloaders[\"test\"]):\n",
    "                self.data, self.labels = data, labels\n",
    "                with self._callback_manager(\"test_batch\"):\n",
    "                    self.test_predictions = self.model(self.data, self.labels)\n",
    "                    self.test_loss_batch = self.loss_func(self.predictions, self.labels)\n",
    "\n",
    "                    if i:\n",
    "                        self.test_loss = self.accumulate_loss(self.test_loss, self.test_loss_batch)\n",
    "                    else:\n",
    "                        self.test_loss = self.test_loss_batch\n",
    "\n",
    "    @contextmanager\n",
    "    def _callback_manager(self, name):\n",
    "        # Is there a way to move the try except block into here?\n",
    "        # Might have to pass in a list of exceptions in here but thats doable\n",
    "        # That way I could run the after callbacks even if the context was cancelled early\n",
    "        # Also would be nice to have a hook to let callbacks know if the batch/epoch/training was cancelled early\n",
    "        # Something like self.epoch_failed = True but more computational than that\n",
    "        self._run_callback(\"before_\" + name)\n",
    "        yield\n",
    "        self._run_callback(\"after_\" + name)\n",
    "\n",
    "\n",
    "    def _run_callback(self, name):\n",
    "        for callback in sorted(self.callbacks, lambda x: x.order):\n",
    "            callback = getattr(callback, name, None)\n",
    "\n",
    "            if callback is not None:\n",
    "                callback(self)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3D_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "027e515360b94f8508ce087551c413c792ad912dc979b64fe23c60a60c965b82"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
